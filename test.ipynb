{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (\n",
    "        sys.version_info.major,\n",
    "        sys.version_info.minor,\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "\n",
    "import carla\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "import yaml\n",
    "import queue\n",
    "\n",
    "class Scene:\n",
    "\n",
    "    def __init__(self, traffic_level=20) -> None:\n",
    "        \n",
    "        self._set_world()\n",
    "        # The world contains the list blueprints that we can use for adding new\n",
    "        # actors into the simulation.\n",
    "        # Synchronous mode\n",
    "        settings = self.world.get_settings()\n",
    "        settings.synchronous_mode = True\n",
    "        settings.fixed_delta_seconds = 1/20\n",
    "        self.world.apply_settings(settings)\n",
    "        \n",
    "        self.spawn_points = self.world.get_map().get_spawn_points()\n",
    "        self.blueprint_lib = self.world.get_blueprint_library()\n",
    "        self.spectator = self.world.get_spectator()\n",
    "        self._set_ego_vehicle()\n",
    "        self._spawn_cars(traffic_level)\n",
    "        self._set_rgb_camera()\n",
    "        self.ego_vehicle.set_autopilot(True)\n",
    "        self._stream_rgb_camera()\n",
    "        self._destroy_actors()\n",
    "        \n",
    "        \n",
    "\n",
    "    def _set_world(self):\n",
    "        self.client = carla.Client('localhost', 2000)\n",
    "        self.client.set_timeout(3.0)\n",
    "\n",
    "        # Once we have a client we can retrieve the world that is currently\n",
    "        # running.\n",
    "        self.world = self.client.get_world()\n",
    "\n",
    "    def _destroy_actors(self):\n",
    "        print('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa')\n",
    "        for actor in self.world.get_actors().filter('*vehicle*'):\n",
    "            actor.destroy()\n",
    "        for actor in self.world.get_actors().filter('*sensor*'):\n",
    "            actor.destroy()\n",
    "        \n",
    "    def _set_ego_vehicle(self, vehicle='tesla.model3'):\n",
    "        self.vehicles_bp = self.blueprint_lib.find(f'vehicle.{vehicle}')\n",
    "        self.ego_vehicle = self.world.try_spawn_actor(self.vehicles_bp, random.choice(self.spawn_points))\n",
    "        self.spectator = self.world.get_spectator() \n",
    "        transform = carla.Transform(self.ego_vehicle.get_transform().transform(carla.Location(x=-4,z=2.5)),self.ego_vehicle.get_transform().rotation) \n",
    "        self.spectator.set_transform(transform)\n",
    "\n",
    "    def _spawn_cars(self, num_cars):\n",
    "        \n",
    "        random.seed(0)\n",
    "\n",
    "        if num_cars>len(self.spawn_points):\n",
    "            print('more cars then spawn points')\n",
    "            num_cars = len(self.spawn_points) - 1\n",
    "\n",
    "        else:\n",
    "            self.spawn_points = self.spawn_points[:num_cars]\n",
    "\n",
    "\n",
    "        # Select some models from the blueprint library\n",
    "        models = ['dodge', 'audi', 'model3', 'mini', 'mustang', 'lincoln', 'prius', 'nissan', 'crown', 'impala']\n",
    "        blueprints = []\n",
    "        for vehicle in self.world.get_blueprint_library().filter('*vehicle*'):\n",
    "            if any(model in vehicle.id for model in models):\n",
    "                blueprints.append(vehicle)\n",
    "\n",
    "        self.vehicles = []\n",
    "\n",
    "        # Take a random sample of the spawn points and spawn some vehicles\n",
    "        for i, spawn_point in enumerate(random.sample(self.spawn_points, num_cars)):\n",
    "            temp = self.world.try_spawn_actor(random.choice(blueprints), spawn_point)\n",
    "            if temp is not None:\n",
    "                self.vehicles.append(temp)\n",
    "                temp.set_autopilot(True)\n",
    "\n",
    "    def _read_camera_setup(self):\n",
    "        pass\n",
    "\n",
    "    def _set_rgb_camera(self):\n",
    "        # Set initial camera translation\n",
    "        camera_init_trans = carla.Transform(carla.Location(z=2))\n",
    "        vehicle_transform = self.ego_vehicle.get_transform()\n",
    "        # print(vehicle_transform.get_matrix())\n",
    "        # Add one of each type of camera\n",
    "        self.camera_bp = self.blueprint_lib.find('sensor.camera.rgb')\n",
    "        self.rgb_camera = self.world.spawn_actor(self.camera_bp, camera_init_trans, attach_to=self.ego_vehicle)\n",
    "        time.sleep(2.0)\n",
    "        self.spectator.set_transform(self.rgb_camera.get_transform())\n",
    "\n",
    "    def _set_lidar(self):\n",
    "        pass\n",
    "\n",
    "    def _set_segmentation_camera(self):\n",
    "        seg_camera_bp = self.blueprint_lib.find('sensor.camera.semantic_segmentation')\n",
    "        self.segmentation_camera = self.world.spawn_actor(seg_camera_bp, self.rgb_camera.get_transform(), attach_to=self.ego_vehicle)\n",
    "        \n",
    "    @staticmethod\n",
    "    def camera_callback(image, data_dict):\n",
    "        image.convert(carla.ColorConverter.Raw)\n",
    "        array = np.frombuffer(image.raw_data, dtype=np.dtype(\"uint8\"))\n",
    "        array = np.reshape(array, (image.height, image.width, 4))\n",
    "        array = array[:, :, :3]\n",
    "        array = array[:, :, ::-1]\n",
    "        global image_g\n",
    "        image_g = array\n",
    "        \n",
    "    def _stream_rgb_camera(self):\n",
    "        # Get gamera dimensions and initialise dictionary                       \n",
    "        image_w = self.camera_bp.get_attribute(\"image_size_x\").as_int()\n",
    "        image_h = self.camera_bp.get_attribute(\"image_size_y\").as_int()\n",
    "        camera_data = {'image': np.zeros((image_h, image_w, 4))}\n",
    "        # Start camera recording\n",
    "        self.rgb_camera.listen(lambda image: self.camera_callback(image, camera_data))\n",
    "        cv2.namedWindow('RGB Camera', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RGB Camera', camera_data['image'])\n",
    "        cv2.waitKey(1)\n",
    "        # Game loop\n",
    "        while True:\n",
    "            \n",
    "            # Imshow renders sensor data to display\n",
    "            cv2.imshow('RGB Camera', camera_data['image'])\n",
    "            \n",
    "            # Quit if user presses 'q'\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                \n",
    "                break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    scene = Scene()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from world import CarlaWorld\n",
    "from ego_vehicle import EgoVehicle\n",
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "import time\n",
    "\n",
    "try:\n",
    "    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (\n",
    "        sys.version_info.major,\n",
    "        sys.version_info.minor,\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "import carla\n",
    "\n",
    "from utils import process_rgb_image, retrive_data, process_depth_image, process_sem_seg_image, process_point_cloud, add_open3d_axis\n",
    "    \n",
    "\n",
    "with open('cfg\\\\vehicle_cfg.yaml', 'r') as f:\n",
    "    vehicle_cfg = yaml.safe_load(f) \n",
    "    \n",
    "with open('cfg\\\\config.yaml', 'r') as f:\n",
    "    cfg = yaml.safe_load(f) \n",
    "    \n",
    "carla_world = CarlaWorld(cfg)\n",
    "carla_world.spawn_actors()\n",
    "bp_lib = carla_world.world.get_blueprint_library()\n",
    "ego_vehicle = EgoVehicle(bp_lib, vehicle_cfg)\n",
    "ego_vehicle.spwan_ego_vehicle(carla_world.world)\n",
    "ego_vehicle.sensor_setup(carla_world.world)\n",
    "ego_vehicle.ego_vehicle.set_autopilot(True)\n",
    "for sensor_name, sensor in ego_vehicle.sensors.items():\n",
    "    sensor.listen(ego_vehicle.sensors_queues[sensor_name].put)\n",
    "carla_world.set_synchronous()\n",
    "point_list = o3d.geometry.PointCloud()\n",
    "\n",
    "# Open3D visualiser for LIDAR and RADAR\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window(\n",
    "    window_name='Carla Lidar',\n",
    "    width=960,\n",
    "    height=540,\n",
    "    left=480,\n",
    "    top=270)\n",
    "vis.get_render_option().background_color = [0.05, 0.05, 0.05]\n",
    "vis.get_render_option().point_size = 1\n",
    "vis.get_render_option().show_coordinate_frame = True\n",
    "add_open3d_axis(vis)\n",
    "frame = 0\n",
    "while True:\n",
    "    data = {}\n",
    "    frame_id = carla_world.tick()\n",
    "    for sensor_name, sensor in ego_vehicle.sensors.items():\n",
    "        data[sensor_name] = retrive_data(ego_vehicle.sensors_queues[sensor_name], frame_id, 2.0)\n",
    "    \n",
    "    rgb_array = process_rgb_image(data['rgb_camera1'])\n",
    "    sem_seg_array = process_sem_seg_image(data['sem_seg_camera1'])\n",
    "    depth_array = process_depth_image(data['depth_camera1'])\n",
    "    process_point_cloud(data['lidar1'], point_list)\n",
    "    if frame == 2:\n",
    "        vis.add_geometry(point_list)\n",
    "    vis.update_geometry(point_list)\n",
    "    \n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "    # # This can fix Open3D jittering issues:\n",
    "    time.sleep(0.005)\n",
    "    frame += 1\n",
    "    cv2.imshow('RGB Camera', rgb_array)\n",
    "    cv2.imshow('Depth Camera', depth_array)\n",
    "    cv2.imshow('Semantic Camera', sem_seg_array)\n",
    "\n",
    "    # Quit if user presses 'q'\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        vis.destroy_window()\n",
    "        \n",
    "        break\n",
    "    break\n",
    "    \n",
    "\n",
    "carla_world.restore()\n",
    "carla_world.destroy_actors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328086, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidar_data = data['lidar1']\n",
    "points = np.frombuffer(lidar_data.raw_data, dtype=np.dtype('f4'))\n",
    "points = np.reshape(points, (int(points.shape[0] / 4), 4))\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([point_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "carla_world.restore()\n",
    "carla_world.destroy_actors()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
